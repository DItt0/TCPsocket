**《FACE-KEG: FAct Checking Explained using KnowledgE Graphs》**


**前人的研究方法：**
1.“通过检索证据句子来推理主张的提取方法”
问题：“虽然这些证据可以作为解释，但往往过于冗长，而且包含了对证明主张不必要的无关信息。”
2.“通过以下方法来解释事实的真实性：(i)从大型通用知识本体（如DBPedia[3]）中提取的语义踪迹和模式；(ii)形式逻辑规则；(iii)半结构化表格或数据库中的归属关系”
问题：以这种方式编写的解释通常不连贯，篇幅过长，且包含无关信息，不像纯文本那样易于阅读和解释。

**文章创新点：**
FACE-KEG框架是一种新型深度学习模型，它能同时预测事实的真实性，并生成支持其决定的连贯解释。在三个大规模数据集上，FACE-KEG的表现优于最先进的基线模型。它首先构建一个知识图谱，然后检索与每个输入声明相关的非结构化文本上下文。然后使用图转换器网络和双向递归神经网络分别对知识图谱和文本上下文进行编码。随后，联合训练一个分类器和一个解码器，前者用于预测声明是否属实，后者用于学习生成自然语言解释，以澄清声明的真实性。我们建议从声明内容、适当的背景环境和与声明相关的结构化概念知识等相互关联的角度来学习输入声明的解释。除了获得语义理解，分析相关上下文还有助于发现间接线索，如输入事实或主张的立场或情感，这对事实检查非常有用。还引入了开放领域、开放主题的辅助知识，这是文献中首次尝试通过直接生成文本解释来解释事实检查，从而以抽象的方式澄清输入事实的真实性。



**FACE-KEG框架:**


<img width="700" alt="image" src="https://github.com/DItt0/TCPsocket/assets/41851418/33b940f8-5bb1-42ec-bb61-441cfe1f772e">
<img width="393" alt="屏幕截图 2023-10-25 213627" src="https://github.com/DItt0/TCPsocket/assets/41851418/b6ed7ced-2ac6-4291-8906-d02ddd70dc77">


构建一个与输入权利要求相关的知识图谱。然后 ，我们从可用的知识库中提取与语句相关的文本上下文，使用双向RNN和图转换器网络分别对相关文本上下文和知识图谱进行编码。随后，我们将联合训练一个分类器和一个解码器，前者可预测输入事实的真假，后者可学习生成有关事实真实性的自然语言解释。我们在FACE-KEG中同时使用了结构化知识图谱和非结构化文本上下文，使两者相互补充 ，以执行可解释的事实检查。这确保了即使在构建的知识图谱中没有评估事实真实性所需的足够背景信息，提取的上下文也能弥补，反之亦然。框架包含了文本编码器、知识图谱转换编码器、可解释的真实性预测三部分组成。

**实验过程发现**：

<img width="700" alt="image" src="https://github.com/DItt0/TCPsocket/assets/41851418/bdcedf77-7850-47cc-a282-cd6e762a6f0f">
<img width="700" alt="image" src="https://github.com/DItt0/TCPsocket/assets/41851418/2c02e8aa-be1f-46af-b5d9-470655d01519">


仅使用图形编码器或仅使用文本编码器时，这两项指标都有所下降，这表明结构化和非结构化知识输入是相辅相成的，有助于真实性预测。
实验发现FACE-KEG在FEVER数据集上的整体表现最好，其次是MultiFC和FakeCOVID数据集。深入分析后发现，这是因为MultiFC和FakeCOVID数据集中在声明在输入文本语料库中没有那么多相关的支持上下文。这些数据集中的一些声明还与较少的相关知识库实体或较多的不必要实体相关联。MultiFC和FakeCOVID 索赔的真实解释长度相对较长，这也使得更难生成。因此实验中也更难生成高质量的解释，集中声明的真实解释也更长。

**发现的不足：**
某些声明的背景知识不足（外部知识库中缺失或FACE-KEG无法检索到）会导致错误的结果，另一个常见的错误是选择相关但不正确的知识实体复制到生成的解释中。
